# Optimized Docker Compose for Production (Hetzner CPX31: 4 CPU, 8GB RAM)

services:
  # Main Bot
  bot:
    build:
      context: .
      dockerfile: Dockerfile.bot
    container_name: chopsticks-bot
    restart: unless-stopped
    env_file: .env
    environment:
      - STORAGE_DRIVER=postgres
      - NODE_ENV=production
      - FUN_PROVIDER=${FUN_PROVIDER:-auto}
      - FUNHUB_URL=${FUNHUB_URL:-http://funhub:8790}
      - FUNHUB_INTERNAL_API_KEY=${FUNHUB_INTERNAL_API_KEY:-}
    volumes:
      - ./data:/app/data
    networks:
      - chopsticks
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      lavalink:
        condition: service_healthy
    mem_limit: 512m
    mem_reservation: 256m
    cpus: '1.0'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Agent Runner (5-10 agents)
  agents:
    build:
      context: .
      dockerfile: Dockerfile.agentrunner
    container_name: chopsticks-agents
    restart: unless-stopped
    env_file: .env
    environment:
      - STORAGE_DRIVER=postgres
      - NODE_ENV=production
      - AGENT_RUNNER_POLL_INTERVAL_MS=10000
      - MAX_AGENTS_PER_RUNNER=10
      - AGENT_CONTROL_URL=${AGENT_CONTROL_URL:-ws://bot:8787}
      - LAVALINK_HOST=${LAVALINK_HOST:-lavalink}
      - LAVALINK_PORT=${LAVALINK_PORT:-2333}
      - LAVALINK_PASSWORD=${LAVALINK_PASSWORD:-youshallnotpass}
    networks:
      - chopsticks
    depends_on:
      postgres:
        condition: service_healthy
      lavalink:
        condition: service_healthy
      bot:
        condition: service_started
    mem_limit: 1g
    mem_reservation: 512m
    cpus: '1.5'
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    container_name: chopsticks-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-chopsticks}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme}
      POSTGRES_DB: ${POSTGRES_DB:-chopsticks}
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - chopsticks
    mem_limit: 512m
    mem_reservation: 256m
    cpus: '0.5'
    command: >
      postgres
      -c shared_buffers=256MB
      -c effective_cache_size=1GB
      -c maintenance_work_mem=64MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c work_mem=2MB
      -c min_wal_size=1GB
      -c max_wal_size=4GB
      -c max_connections=100
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-chopsticks}"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: chopsticks-redis
    restart: unless-stopped
    command: >
      redis-server
      --maxmemory 128mb
      --maxmemory-policy allkeys-lru
      --save 60 1000
      --appendonly yes
    volumes:
      - redis_data:/data
    networks:
      - chopsticks
    mem_limit: 256m
    mem_reservation: 128m
    cpus: '0.25'
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # Lavalink Music Server
  lavalink:
    image: ghcr.io/lavalink-devs/lavalink:4
    container_name: chopsticks-lavalink
    restart: unless-stopped
    environment:
      - _JAVA_OPTIONS=-Xmx1G -Xms512M
      - SERVER_PORT=2333
      - LAVALINK_SERVER_PASSWORD=${LAVALINK_PASSWORD:-youshallnotpass}
    volumes:
      - ./lavalink/application.yml:/opt/Lavalink/application.yml:ro
      - ./lavalink/plugins:/opt/Lavalink/plugins:ro
    networks:
      - chopsticks
    mem_limit: 1536m
    mem_reservation: 768m
    cpus: '1.5'
    healthcheck:
      test: ["CMD-SHELL", "curl -f -H 'Authorization: ${LAVALINK_PASSWORD:-youshallnotpass}' http://localhost:2333/version || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Dashboard (Optional - lightweight)
  dashboard:
    build:
      context: .
      dockerfile: Dockerfile.bot
      args:
        - BUILD_TARGET=dashboard
    container_name: chopsticks-dashboard
    restart: unless-stopped
    env_file: .env
    environment:
      - NODE_ENV=production
      - STORAGE_DRIVER=postgres
      - REDIS_URL=redis://redis:6379
    command: ["npm", "run", "dashboard"]
    healthcheck:
      test: ["CMD-SHELL", "node -e \"require('http').get('http://localhost:8788/health', r => process.exit(r.statusCode === 200 ? 0 : 1)).on('error', () => process.exit(1))\""]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    # Ports exposed via Caddy, but kept for direct access if needed
    ports:
      - "8788:8788"
    networks:
      - chopsticks
    depends_on:
      - postgres
      - redis
    mem_limit: 256m
    mem_reservation: 128m
    cpus: '0.5'
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
    profiles: ["dashboard"]  # Enabled by start.sh for production bring-up

  # FunHub Variant API (Optional)
  funhub:
    build:
      context: .
      dockerfile: Dockerfile.bot
    container_name: chopsticks-funhub
    restart: unless-stopped
    env_file: .env
    environment:
      - NODE_ENV=production
      - FUNHUB_PORT=8790
      - FUNHUB_REQUIRE_API_KEY=${FUNHUB_REQUIRE_API_KEY:-true}
      - FUNHUB_INTERNAL_API_KEY=${FUNHUB_INTERNAL_API_KEY:-}
      - FUNHUB_API_KEYS=${FUNHUB_API_KEYS:-}
      - FUNHUB_CORS_ORIGINS=${FUNHUB_CORS_ORIGINS:-}
      - FUNHUB_RATE_LIMIT_MAX=${FUNHUB_RATE_LIMIT_MAX:-120}
      - FUNHUB_RATE_LIMIT_WINDOW_MS=${FUNHUB_RATE_LIMIT_WINDOW_MS:-60000}
    command: ["npm", "run", "funhub"]
    healthcheck:
      test: ["CMD-SHELL", "node -e \"require('http').get('http://localhost:8790/health', r => process.exit(r.statusCode === 200 ? 0 : 1)).on('error', () => process.exit(1))\""]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    ports:
      - "8790:8790"
    networks:
      - chopsticks
    mem_limit: 192m
    mem_reservation: 96m
    cpus: '0.30'
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
    profiles: ["fun"]

  # Caddy Reverse Proxy
  caddy:
    image: caddy:2-alpine
    container_name: chopsticks-caddy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
    networks:
      - chopsticks
    depends_on:
      - dashboard
    mem_limit: 128m
    cpus: '0.25'
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
    profiles: ["dashboard"]

  # Prometheus Metrics (Optional)
  prometheus:
    image: prom/prometheus:latest
    container_name: chopsticks-prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=7d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/alerts:/etc/prometheus/alerts:ro
      - prometheus_data:/prometheus
    networks:
      - chopsticks
    ports:
      - "9090:9090"
    mem_limit: 256m
    cpus: '0.25'
    profiles: ["monitoring"]
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # Grafana (Optional)
  grafana:
    image: grafana/grafana:latest
    container_name: chopsticks-grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_SERVER_ROOT_URL=${GRAFANA_ROOT_URL:-http://localhost:3001}
      - GF_INSTALL_PLUGINS=redis-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
    ports:
      - "3001:3000"
    networks:
      - chopsticks
    depends_on:
      - prometheus
    mem_limit: 256m
    cpus: '0.25'
    profiles: ["monitoring"]
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # Dozzle Live Logs UI (Optional Ops Cockpit)
  dozzle:
    image: amir20/dozzle:latest
    container_name: chopsticks-dozzle
    restart: unless-stopped
    environment:
      - DOZZLE_NO_ANALYTICS=true
      - DOZZLE_LEVEL=info
    ports:
      - "9999:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - chopsticks
    mem_limit: 128m
    cpus: '0.20'
    profiles: ["ops"]
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  caddy_data:
    driver: local
  caddy_config:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

networks:
  chopsticks:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.0.0/16
